---
title: 'Ä°lk AdÄ±mlar: Ä°ris SÄ±nÄ±flandÄ±rma UygulamasÄ±'
date: '2022-02-5'
tags: ['Makine Ã–ÄŸrenmesi', Uygulama]
summary: 'Iris veri seti ile sÄ±nÄ±flandÄ±rma uygulamasÄ±.'
---

<TOCInline toc={props.toc} asDisclosure />
## GiriÅŸ 
Hobi olarak botanik ile uÄŸraÅŸtÄ±ÄŸÄ±mÄ±zÄ±, ve bulduÄŸumuz iris (sÃ¼sen) Ã§iÃ§eklerinin hangi tÃ¼re ait
olduÄŸunu Ã¶ÄŸrenmek istediÄŸimizi varsayalÄ±m. Her bir Ã§iÃ§eÄŸin Ã§anak (sepal) ve taÃ§ yapraklarÄ±nÄ±n (petals)
uzunluk ve geniÅŸliklerini santimetre cinsiden kaydetmiÅŸ olalÄ±m.

AyrÄ±ca elimizde uzman bir botanikÃ§inin hazÄ±rladÄ±ÄŸÄ±, yaptÄ±ÄŸÄ± Ã¶lÃ§Ã¼mlerle _setosa, versicolor, virginica_ tÃ¼rlerinden birine ait olduÄŸunu belirleyebildiÄŸi bir veri seti daha var. Hobi botanikÃ§isinin doÄŸada karÅŸÄ±laÅŸtÄ±ÄŸÄ± iris tÃ¼rlerinin sadece bunlar olduÄŸunu varsayalÄ±m.

Burada amacÄ±mÄ±z, tÃ¼rÃ¼ bilinen bu irislerin Ã¶lÃ§Ã¼mlerinden Ã¶ÄŸrenebilecek bir makine Ã¶ÄŸrenme modeli oluÅŸturmak ve bu modelle yeni bir iris verisi iÃ§in, hangi tÃ¼re ait olduÄŸunu tahmin edebilmektir.

![iris Ã§iÃ§eÄŸinin taÃ§ ve Ã§anak yapraÄŸÄ±nÄ±n, geniÅŸlik ve uzunluÄŸunu gÃ¶steren resim](/static/images/Makine_Ogrenmesi/iris_classification/sepal_vs_petal.png)

DoÄŸru iris tÃ¼rÃ¼ne ait olduÄŸunu bildiÄŸimiz veriler olduÄŸu iÃ§in, bu bir _supervised learning_ problemidir. Bu problemde iris tÃ¼rlerinden birini tahmin etmeye Ã§alÄ±ÅŸacaÄŸÄ±z. Yani aslÄ±nda bu bir _classification (sÄ±nÄ±flandÄ±rma)_ problemi. Her bir farklÄ± tÃ¼re _class_ diyeceÄŸiz. Veri setimizdeki her bir iris bu Ã¼Ã§ _class_ dan birine ait olacaÄŸÄ± iÃ§in bu problem _three-class classification problem_ (Ã¼Ã§ sÄ±nÄ±flÄ±, sÄ±nÄ±flandÄ±rma problemi.) olacaktÄ±r.

Her bir Ã§iÃ§ek iÃ§in beklenen Ã§Ä±ktÄ± deÄŸeri, bu Ã§iÃ§eÄŸin hangi tÃ¼re ait olduÄŸudur. Ã‡iÃ§eÄŸin hangi tÃ¼re ait olduÄŸu onun _label'Ä±_ (etiketi) olacaktÄ±r.

### Veri setimiz

Veri seti olarak, istatistik ve makine Ã¶ÄŸrenmesi Ã¶rneklerinde sÄ±kÃ§a kullanÄ±lan 'Iris' veri setini kullanacaÄŸÄ±z. `scikit-learn` kÃ¼tÃ¼phanesinde `datasets` modÃ¼lÃ¼nde bulunmaktadÄ±r. `load_iris` fonksiyonu ile yÃ¼klenebilir.

```py
from sklearn.datasets import load_iris
iris_dataset = load_iris()
```

Bu kod ile veri setimizi iris_dataset deÄŸiÅŸkenine atamÄ±ÅŸ olduk. Bu veri seti Bunch Object olduÄŸu iÃ§in, sÃ¶zlÃ¼k gibi 'keys' ve 'values' deÄŸerleri barÄ±ndÄ±rÄ±r.

```py:In
print("Keys of iris_dataset: \n{}".format(iris_dataset.keys()))
```

```:Out
Keys of iris_dataset:
dict_keys(['target_names', 'feature_names', 'DESCR', 'data', 'target'])
```

Yani veri setindeki keylerimiz: `target_names`, `feature_names`, `DESCR`, `data`, `target`. BunlarÄ±n her biri, iÃ§inde deÄŸerler (values) barÄ±ndÄ±rmakta.

`DESCR` keyi iÃ§inde veri seti hakkÄ±nda kÄ±sa bir aÃ§Ä±klama iÃ§ermekte.

`feature_names` keyi, Ã§iÃ§eklerin Ã¶zelliklerinin aÃ§Ä±klamasÄ±nÄ± string olarak barÄ±ndÄ±rÄ±r. (sepal width, sepal length, )

`data` adÄ± Ã¼zerinde verileri barÄ±ndÄ±rÄ±r. (numpy dizisi olarak)

`target_names` iÃ§inde Ã§iÃ§eklerin tÃ¼rleri bulunur (string olarak numpy dizisi iÃ§inde)

`target` iÃ§inde Ã§iÃ§eklerin hangi tÃ¼re ait olduÄŸunu belirten 0 dan 2 ye kadar numaralandÄ±rÄ±larak sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ bir numpy dizisi bulunur.
0=setosa, 1=versicolor, 2=virginica

### Training and Testing Data (EÄŸitim ve Test Verileri)

Bu verileri kullanarak yeni Ã¶lÃ§tÃ¼ÄŸÃ¼mÃ¼z Ã§iÃ§eklerin tÃ¼rlerini makine Ã¶ÄŸrenmesi ile tahmin ettirmeye Ã§alÄ±ÅŸacaÄŸÄ±z. Ancak modelimizi yeni Ã¶lÃ§Ã¼mler Ã¼zerinde uygulamadan Ã¶nce gerÃ§ekten gerÃ§ekten iÅŸe yarayÄ±p yaramdÄ±ÄŸÄ±na bakarak bu modele gÃ¼venip gÃ¼venemeyeceÄŸimizi bilmemiz gerekir.

Ancak ÅŸÃ¶yle bir durum var. Modeli kurmak iÃ§in kullandÄ±ÄŸÄ±mÄ±z verileri, modeli deÄŸerlendirmek iÃ§in kullanamÄ±yoruz ğŸ˜¢ Bunun nedenini kÄ±saca aÃ§Ä±klayacak olursam; modelimiz bÃ¼tÃ¼n training set verilerini hatÄ±rlayacaÄŸÄ± iÃ§in, training set verilerinde Ã§iÃ§ek tÃ¼rlerini her daim doÄŸru tahmin edecek. Ancak bu "hatÄ±rlama" ile oluÅŸturulan modele yeni bir veri seti verdiÄŸimiz zaman bu farklÄ± veri setinde bu hatÄ±rlamayÄ± yapamayacak. KÄ±sacasÄ± baÅŸka veri setlerinde doÄŸru tahminler yapamayacak.

> ArtÄ±k terimleri Ã§evirmeye Ã§alÄ±ÅŸmayacaÄŸÄ±m Ã§Ã¼nkÃ¼ bÄ±ktÄ±m ğŸ¤¦â€â™‚ï¸. Ä°ngilizcelerinden devam edeceÄŸim.

Modelimizin performansÄ±nÄ± gÃ¶rmek iÃ§in veri setimizi 2 ye bÃ¶leceÄŸiz. Bir bÃ¶lÃ¼mÃ¼ ile machine learning modelimizi oluÅŸturacaÄŸÄ±z. Buna _training data_ ya da _training set_ diyoruz. Kalan verilerimizi ise modelimizin ne kadar iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenmek iÃ§in kullanacaÄŸÄ±z. Buna da _test data_ ya da _test set_ diyoruz.

`scikit-learn` iÃ§erisinde bulunan `train_test_split` fonksiyonu sizin iÃ§in veri setini ÅŸÃ¶Ã¶yle gÃ¼zelce bir karÄ±ÅŸtÄ±rÄ±r ve 75% ini training set, kalan 25% ini ise test set yapar. Ne kadarÄ±nÄ±n training set, ne kadarÄ±nÄ±n test set olacaÄŸÄ± keyfidir ancak bu 75% e 25% kuralÄ± gayet iyidir.

`scikit-learn` de data bÃ¼yÃ¼k X ile gÃ¶sterilirken label lar kÃ¼Ã§Ã¼k y ile gÃ¶sterilir. Bu notasyon matematikteki $$f(x)=y$$ standart formÃ¼lasyonundan gelmektedir.

ÅŸimdi `train_test_split` fonksiyonunun kullanÄ±mÄ±nÄ± gÃ¶relim.

```py
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    iris_dataset['data'], iris_dataset['target'], random_state=0)
```

Bu fonksiyon veriyi 2 ye bÃ¶lmeden Ã¶nce karÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ± sÃ¶ylemiÅŸtik. Yani siz bu fonksiyonu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zda, seÃ§eceÄŸi veriler buradakilerden farklÄ± olacaktÄ±. Burada `random_state=0` parametresi ile bunun Ã¶nÃ¼ne geÃ§tik. `random-state` iÃ§in detaylÄ± bilgiye [_Buradan_](https://scikit-learn.org/stable/glossary.html#term-random_state) ulaÅŸabilirsiniz.

Åimdi elimizdeki `X_train` veri setindeki satÄ±rlarÄ±n 75% ini, `X_test` ise 25% ini iÃ§ermekte.

## Verinin Ä°ncelenmesi

Verimizi incelemek, verideki anormallikleri ve tutarsÄ±zlÄ±klarÄ± tespit etmek iÃ§in Ã¶nemlidir. Ve veriyi incelemenin en gÃ¼zel ve etkili yolu veriyi gÃ¶rselleÅŸtirmektir. Bunun iÃ§in _scatter plot_ kullanabiliriz. Ancak burdaki veri gibi birden fazla Ã¶zellik varsa bunlarÄ±n hepsini _scatter plot_ ile Ã§izdiremeyiz. Onun yerine _pair plot_ kullanabiliriz. Burada olduÄŸu gibi az sayÄ±da Ã¶zelliÄŸiniz varsa (bizim veri setimizde bu sayÄ± 4) _pair plot_ kullanmak oldukÃ§a mantÄ±klÄ± olur ki kendisi tÃ¼m olabilecek Ã¶zellik eÅŸleÅŸmelerine bakar, lakin bÃ¼tÃ¼n Ã¶zelliklerinin birbiriyle etkileÅŸimine tek bir seferde bakamaz. Yani bu gÃ¶rselleÅŸtirme ile verinin bazÄ± ilginÃ§ etkileÅŸimlerini gÃ¶remeyebiliriz. BurayÄ± tam anlatamadÄ±m ancak plot Ã§Ä±ktÄ±sÄ±nÄ± gÃ¶rÃ¼nce daha iyi anlayacaksÄ±nÄ±z... (umarÄ±m ğŸ˜).

GrafiÄŸi Ã§izdirmek iÃ§in Ã¶nce NumPy dizisini pandas DataFrame ine dÃ¶nÃ¼ÅŸtÃ¼rmek gerekiyor. Pandas'Ä±n `scatter_matrix` adÄ±nda pair plot oluÅŸturma fonksiyonu var. Matrixin kÃ¶ÅŸegeninde her bir Ã¶zelliÄŸin histogramÄ± bulunur.

```py
# X_train deki verilerden bir dataframe oluÅŸturalÄ±m.
# iris_dataset.feature_names iÃ§indeki stringleri kullanarak sÃ¼tunlarÄ± etiketleyelim
iris_dataframe = pd.DataFrame(X_train, columns=iris_dataset.feature_names)
# dataframeden, y_traine gÃ¶re renklendirilmiÅŸ scatter matrix oluÅŸturalÄ±m
grr = pd.scatter_matrix(iris_dataframe, c=y_train, figsize=(15, 15), marker='o',
hist_kwds={'bins': 20}, s=60, alpha=.8, cmap=mglearn.cm3)
```

![iris](/static/images/Makine_Ogrenmesi/iris_classification/scatter_matrix_iris.png)

Grafiklere bakarak, tÃ¼rlerin sepal ve petal Ã¶lÃ§Ã¼mlerine gÃ¶re oldukÃ§a iyi bir biÃ§imde birbirlerinden ayrÄ±lmÄ±ÅŸ olduklarÄ±nÄ± gÃ¶rebiliyoruz. Bu makine Ã¶ÄŸrenmesi modelimizin bÃ¼yÃ¼k ihtimalle onlarÄ± ayrÄ±ÅŸtÄ±rmayÄ± Ã¶ÄŸrenebileceÄŸini gÃ¶steriyor.

## Ä°lk Modelimiz: k-Nearest Neighbors

Åimdi asÄ±l yapmamÄ±z gerekeni, makine Ã¶ÄŸrenmesi modelimizi oluÅŸturmaya baÅŸlayabiliriz.`scikit-learn` iÃ§inde birsÃ¼rÃ¼ classification algoritmasÄ± var. Biz burada _k-Nearest Neighbors_ algoritmasÄ±nÄ± kullanacaÄŸÄ±z. Bu modeli oluÅŸturmak iÃ§in tek yapmamÄ±z gereken elimizdeki training setini bir yerde depolamak. Yeni veriler iÃ§in tahmin yapmak iÃ§in algoritma bu yeni noktalara en yakÄ±n training set noktasÄ±nÄ± (komÅŸu) kullanÄ±r ve training set noktasÄ±na ait classÄ± (0,1,2) atar. (burada nokta dediÄŸim ÅŸey grafikteki nokta.)

k-Nearest Neighbors daki "k" ile, verideki en yakÄ±n komÅŸuya bakmak yerine istediÄŸimiz kadar komÅŸuya (Ã¶rneÄŸin 1 komÅŸu yerine 3 yada 5 komÅŸu) bakarÄ±z. SonrasÄ±nda hangi komÅŸu daha fazlaysa ona gÃ¶re labelÄ±mÄ±zÄ± belirleriz.

Scikit-learn'deki tÃ¼m makine Ã¶ÄŸrenimi modelleri, Estimator class'larÄ± adÄ± verilen kendi classlarÄ±nda uygulanÄ±r. k-nearest neighbors classification algoritmasÄ±, `KNeighborsClassifier` classÄ±ndaki `neighbors` modÃ¼lÃ¼ ile uygulanÄ±r. Bunu modelin parametreleri ile ayarlayabiliriz. `KNeighborsClassifier` Ä±n en Ã¶nemli parametresi komÅŸu sayÄ±sÄ±dÄ±r. Ki biz burada onu 1 alacaÄŸÄ±z.

```py
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=1)
```

Training set Ã¼zerinde modelimizi oluÅŸturmak iÃ§in knn objesinin `fit` metodunu kullanacaÄŸÄ±z.

```py:In
knn.fit(X_train, y_train)
```

```py:Out
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
metric_params=None, n_jobs=1, n_neighbors=1, p=2, weights='uniform')
```

`fit` metodu bize knn objesini dÃ¶ndÃ¼rdÃ¼. ClassifierÄ±mÄ±zÄ± string olarak gÃ¶rebiliyoruz. Hemen her ÅŸey default deÄŸerinde iken, ayarladÄ±ÄŸÄ±mÄ±z `n_neighbors` deÄŸeri 1 e eÅŸit. (default deÄŸeri normalde 5) DiÄŸer parametreleri ÅŸuan iÃ§in dÃ¼ÅŸÃ¼nmeye gerek yok.

### Tahmin Yapma

ArtÄ±k kurduÄŸumuz modelle tÃ¼rlerini bilmediÄŸimiz veri Ã¼zerinde tahmin yaptÄ±rtabiliriz. Bunun iÃ§in knn objesinin `predict` metodunu kullanacaÄŸÄ±z. Ormanda bir iris Ã§iÃ§eÄŸi bulduÄŸumuzu dÃ¼ÅŸÃ¼nelim ve bu Ã§iÃ§eÄŸin sepal_length deÄŸeri 5cm, sepal_width deÄŸeri 2.9 cm, petal_length deÄŸeri 1cm, ve petal_width deÄŸer 0.2 olsun. Bu Ã§iÃ§eÄŸin tÃ¼rÃ¼ ne olabilir? Ã–lÃ§tÃ¼ÄŸÃ¼mÃ¼z verileri NumPy dizisine ekleyelim. Elimizde 1 Ã¶rnekli, 4 Ã¶zellikli bir dizi olmasÄ± gerekiyor.

```py:In
X_new = np.array([[5, 2.9, 1, 0.2]])
print("X_new.shape: {}".format(X_new.shape))
```

```:Out
X_new.shape: (1, 4)
```

> Ã–lÃ§Ã¼mlerini yaptÄ±ÄŸÄ±mÄ±z tek Ã§iÃ§eÄŸi 2 boyutlu NumPy dizisinde tutuyoruz Ã§Ã¼nkÃ¼ scikit learn veri olarak 2 boyutlu diziler kullanÄ±yor

```py:In
prediction = knn.predict(X_new)
print("Prediction: {}".format(prediction))
print("Predicted target name: {}".format(
iris_dataset['target_names'][prediction]))
```

```:Out
Prediction: [0]
Predicted target name: ['setosa']
```

Modelimiz yeni irisimizin classÄ±nÄ± 0 olarak belirledi. Bu da setosa ya tekabÃ¼l ediyor. Modelimiz bunu buldu. Ä°yi ama bunun doÄŸru olduÄŸunu nerden bilecez? ğŸ§ Ä°ÅŸte bÃ¼tÃ¼n olay bu! Bu Ã¶rneÄŸin hangi tÃ¼re ait olduÄŸunu bilmiyoruz.

### Modelin DeÄŸerlendirilmesi

Ä°ÅŸte burada daha Ã¶nce oluÅŸturduÄŸumuz test set verisi Ã¶nem arz ediyor. Bundaki veriler model oluÅŸturmak iÃ§in kullanÄ±lmadÄ±. Ancak test setteki Ã§iÃ§eklerin hangi tÃ¼re ait olduÄŸunu biliyoruz. Ã–yleyse her bir Ã§iÃ§ek iÃ§in tahmin yapabilir ve bunlarÄ± doÄŸrularÄ± ile kÄ±yaslayabiliriz. Modelin ne kadar iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenmek iÃ§in _accuracy_'i hesaplayabiliriz.

```py:In
y_pred = knn.predict(X_test)
print("Test set predictions:\n {}".format(y_pred))
```

```:Out
Test set predictions:
    [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0 2]
```

```py:In
print("Test set score: {:.2f}".format(np.mean(y_pred == y_test)))
```

```:Out
Test set score: 0.97
```

AyrÄ±ca, knn objesinin `score` metodu ile test set'in _accuracy_ sini hesaplatabiliriz.

```py:In
print("Test set score: {:.2f}".format(knn.score(X_test, y_test)))
```

```:Out
Test set score: 0.97
```

Bu model iÃ§in test setin _accuracy_ deÄŸeri 0.97 Ã§Ä±ktÄ±, bu da modelimizin test setteki irislerin 97% sini doÄŸru tahmin ettiÄŸi anlamÄ±na geliyor. Yani matematiksel varsayÄ±m olarak "Bu model yeni Ã§iÃ§eklerin tÃ¼rÃ¼nÃ¼ 97% ihtimalle doÄŸru tahmin eder" diyebiliriz. Hobi olarak botanikle uÄŸraÅŸan biri olarak tahminler iÃ§in bu model yeterince gÃ¼venilir bir model.
