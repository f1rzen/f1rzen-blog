---
title: 'İlk Adımlar: İris Sınıflandırma Uygulaması'
date: '2022-02-5'
tags: ['Makine Öğrenmesi', Uygulama]
summary: 'Iris veri seti ile sınıflandırma uygulaması.'
---

Hobi olarak botanik ile uğraştığımızı, ve bulduğumuz iris (süsen) çiçeklerinin hangi türe ait olduğunu öğrenmek istediğimizi varsayalım. Her bir çiçeğin çanak (sepal) ve taç yapraklarının (petals) uzunluk ve genişliklerini santimetre cinsiden kaydetmiş olalım.

Ayrıca elimizde uzman bir botanikçinin hazırladığı, yaptığı ölçümlerle _setosa, versicolor, virginica_ türlerinden birine ait olduğunu belirleyebildiği bir veri seti daha var. Hobi botanikçisinin doğada karşılaştığı iris türlerinin sadece bunlar olduğunu varsayalım.

Burada amacımız, türü bilinen bu irislerin ölçümlerinden öğrenebilecek bir makine öğrenme modeli oluşturmak ve bu modelle yeni bir iris verisi için, hangi türe ait olduğunu tahmin edebilmektir.

![iris çiçeğinin taç ve çanak yaprağının, genişlik ve uzunluğunu gösteren resim](/static/images/Makine_Ogrenmesi/iris_classification/sepal_vs_petal.png)

Doğru iris türüne ait olduğunu bildiğimiz veriler olduğu için, bu bir _supervised learning_ problemidir. Bu problemde iris türlerinden birini tahmin etmeye çalışacağız. Yani aslında bu bir _classification (sınıflandırma)_ problemi. Her bir farklı türe _class_ diyeceğiz. Veri setimizdeki her bir iris bu üç _class_ dan birine ait olacağı için bu problem _three-class classification problem_ (üç sınıflı, sınıflandırma problemi.) olacaktır.

Her bir çiçek için beklenen çıktı değeri, bu çiçeğin hangi türe ait olduğudur. Çiçeğin hangi türe ait olduğu onun _label'ı_ (etiketi) olacaktır.

### Veri setimiz

Veri seti olarak, istatistik ve makine öğrenmesi örneklerinde sıkça kullanılan 'Iris' veri setini kullanacağız. `scikit-learn` kütüphanesinde `datasets` modülünde bulunmaktadır. `load_iris` fonksiyonu ile yüklenebilir.

```py
from sklearn.datasets import load_iris
iris_dataset = load_iris()
```

Bu kod ile veri setimizi iris_dataset değişkenine atamış olduk. Bu veri seti Bunch Object olduğu için, sözlük gibi 'keys' ve 'values' değerleri barındırır.

```py:In
print("Keys of iris_dataset: \n{}".format(iris_dataset.keys()))
```

```:Out
Keys of iris_dataset:
dict_keys(['target_names', 'feature_names', 'DESCR', 'data', 'target'])
```

Yani veri setindeki keylerimiz: `target_names`, `feature_names`, `DESCR`, `data`, `target`. Bunların her biri, içinde değerler (values) barındırmakta.

`DESCR` keyi içinde veri seti hakkında kısa bir açıklama içermekte.

`feature_names` keyi, çiçeklerin özelliklerinin açıklamasını string olarak barındırır. (sepal width, sepal length, )

`data` adı üzerinde verileri barındırır. (numpy dizisi olarak)

`target_names` içinde çiçeklerin türleri bulunur (string olarak numpy dizisi içinde)

`target` içinde çiçeklerin hangi türe ait olduğunu belirten 0 dan 2 ye kadar numaralandırılarak sınıflandırılmış bir numpy dizisi bulunur.
0=setosa, 1=versicolor, 2=virginica

### Training and Testing Data (Eğitim ve Test Verileri)

Bu verileri kullanarak yeni ölçtüğümüz çiçeklerin türlerini makine öğrenmesi ile tahmin ettirmeye çalışacağız. Ancak modelimizi yeni ölçümler üzerinde uygulamadan önce gerçekten gerçekten işe yarayıp yaramdığına bakarak bu modele güvenip güvenemeyeceğimizi bilmemiz gerekir.

Ancak şöyle bir durum var. Modeli kurmak için kullandığımız verileri, modeli değerlendirmek için kullanamıyoruz 😢 Bunun nedenini kısaca açıklayacak olursam; modelimiz bütün training set verilerini hatırlayacağı için, training set verilerinde çiçek türlerini her daim doğru tahmin edecek. Ancak bu "hatırlama" ile oluşturulan modele yeni bir veri seti verdiğimiz zaman bu farklı veri setinde bu hatırlamayı yapamayacak. Kısacası başka veri setlerinde doğru tahminler yapamayacak.

> Artık terimleri çevirmeye çalışmayacağım çünkü bıktım 🤦‍♂️. İngilizcelerinden devam edeceğim.

Modelimizin performansını görmek için veri setimizi 2 ye böleceğiz. Bir bölümü ile machine learning modelimizi oluşturacağız. Buna _training data_ ya da _training set_ diyoruz. Kalan verilerimizi ise modelimizin ne kadar iyi çalıştığını öğrenmek için kullanacağız. Buna da _test data_ ya da _test set_ diyoruz.

`scikit-learn` içerisinde bulunan `train_test_split` fonksiyonu sizin için veri setini şööyle güzelce bir karıştırır ve 75% ini training set, kalan 25% ini ise test set yapar. Ne kadarının training set, ne kadarının test set olacağı keyfidir ancak bu 75% e 25% kuralı gayet iyidir.

`scikit-learn` de data büyük X ile gösterilirken label lar küçük y ile gösterilir. Bu notasyon matematikteki $$f(x)=y$$ standart formülasyonundan gelmektedir.

şimdi `train_test_split` fonksiyonunun kullanımını görelim.

```py
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    iris_dataset['data'], iris_dataset['target'], random_state=0)
```

Bu fonksiyon veriyi 2 ye bölmeden önce karıştırdığını söylemiştik. Yani siz bu fonksiyonu çalıştırdığınızda, seçeceği veriler buradakilerden farklı olacaktı. Burada `random_state=0` parametresi ile bunun önüne geçtik. `random-state` için detaylı bilgiye [_Buradan_](https://scikit-learn.org/stable/glossary.html#term-random_state) ulaşabilirsiniz.

Şimdi elimizdeki `X_train` veri setindeki satırların 75% ini, `X_test` ise 25% ini içermekte.

## Verimize Bakalım

Verimizi incelemek, verideki anormallikleri ve tutarsızlıkları tespit etmek için önemlidir. Ve veriyi incelemenin en güzel ve etkili yolu veriyi görselleştirmektir. Bunun için _scatter plot_ kullanabiliriz. Ancak burdaki veri gibi birden fazla özellik varsa bunların hepsini _scatter plot_ ile çizdiremeyiz. Onun yerine _pair plot_ kullanabiliriz. Burada olduğu gibi az sayıda özelliğiniz varsa (bizim veri setimizde bu sayı 4) _pair plot_ kullanmak oldukça mantıklı olur ki kendisi tüm olabilecek özellik eşleşmelerine bakar, lakin bütün özelliklerinin birbiriyle etkileşimine tek bir seferde bakamaz. Yani bu görselleştirme ile verinin bazı ilginç etkileşimlerini göremeyebiliriz. Burayı tam anlatamadım ancak plot çıktısını görünce daha iyi anlayacaksınız... (umarım 😐).

Grafiği çizdirmek için önce NumPy dizisini pandas DataFrame ine dönüştürmek gerekiyor. Pandas'ın `scatter_matrix` adında pair plot oluşturma fonksiyonu var. Matrixin köşegeninde her bir özelliğin histogramı bulunur.

```py
# X_train deki verilerden bir dataframe oluşturalım.
# iris_dataset.feature_names içindeki stringleri kullanarak sütunları etiketleyelim
iris_dataframe = pd.DataFrame(X_train, columns=iris_dataset.feature_names)
# dataframeden, y_traine göre renklendirilmiş scatter matrix oluşturalım
grr = pd.scatter_matrix(iris_dataframe, c=y_train, figsize=(15, 15), marker='o',
hist_kwds={'bins': 20}, s=60, alpha=.8, cmap=mglearn.cm3)
```

![iris](/static/images/Makine_Ogrenmesi/iris_classification/scatter_matrix_iris.png)

Grafiklere bakarak, türlerin sepal ve petal ölçümlerine göre oldukça iyi bir biçimde birbirlerinden ayrılmış olduklarını görebiliyoruz. Bu makine öğrenmesi modelimizin büyük ihtimalle onları ayrıştırmayı öğrenebileceğini gösteriyor.

## İlk Modelimiz: k-Nearest Neighbors

Şimdi asıl yapmamız gerekeni, makine öğrenmesi modelimizi oluşturmaya başlayabiliriz.`scikit-learn` içinde birsürü classification algoritması var. Biz burada _k-Nearest Neighbors_ algoritmasını kullanacağız. Bu modeli oluşturmak için tek yapmamız gereken elimizdeki training setini bir yerde depolamak. Yeni veriler için tahmin yapmak için algoritma bu yeni noktalara en yakın training set noktasını (komşu) kullanır ve training set noktasına ait classı (0,1,2) atar. (burada nokta dediğim şey grafikteki nokta.)

k-Nearest Neighbors daki "k" ile, verideki en yakın komşuya bakmak yerine istediğimiz kadar komşuya (örneğin 1 komşu yerine 3 yada 5 komşu) bakarız. Sonrasında hangi komşu daha fazlaysa ona göre labelımızı belirleriz.

Scikit-learn'deki tüm makine öğrenimi modelleri, Estimator class'ları adı verilen kendi classlarında uygulanır. k-nearest neighbors classification algoritması, `KNeighborsClassifier` classındaki `neighbors` modülü ile uygulanır. Bunu modelin parametreleri ile ayarlayabiliriz. `KNeighborsClassifier` ın en önemli parametresi komşu sayısıdır. Ki biz burada onu 1 alacağız.

```py
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=1)
```

Training set üzerinde modelimizi oluşturmak için knn objesinin `fit` metodunu kullanacağız.

```py:In
knn.fit(X_train, y_train)
```

```py:Out
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
metric_params=None, n_jobs=1, n_neighbors=1, p=2, weights='uniform')
```

`fit` metodu bize knn objesini döndürdü. Classifierımızı string olarak görebiliyoruz. Hemen her şey default değerinde iken, ayarladığımız `n_neighbors` değeri 1 e eşit. (default değeri normalde 5) Diğer parametreleri şuan için düşünmeye gerek yok.

## Tahmin Yapma

Artık kurduğumuz modelle türlerini bilmediğimiz veri üzerinde tahmin yaptırtabiliriz. Bunun için knn objesinin `predict` metodunu kullanacağız. Ormanda bir iris çiçeği bulduğumuzu düşünelim ve bu çiçeğin sepal_length değeri 5cm, sepal_width değeri 2.9 cm, petal_length değeri 1cm, ve petal_width değer 0.2 olsun. Bu çiçeğin türü ne olabilir? Ölçtüğümüz verileri NumPy dizisine ekleyelim. Elimizde 1 örnekli, 4 özellikli bir dizi olması gerekiyor.

```py:In
X_new = np.array([[5, 2.9, 1, 0.2]])
print("X_new.shape: {}".format(X_new.shape))
```

```:Out
X_new.shape: (1, 4)
```

> Ölçümlerini yaptığımız tek çiçeği 2 boyutlu NumPy dizisinde tutuyoruz çünkü scikit learn veri olarak 2 boyutlu diziler kullanıyor

```py:In
prediction = knn.predict(X_new)
print("Prediction: {}".format(prediction))
print("Predicted target name: {}".format(
iris_dataset['target_names'][prediction]))
```

```:Out
Prediction: [0]
Predicted target name: ['setosa']
```

Modelimiz yeni irisimizin classını 0 olarak belirledi. Bu da setosa ya tekabül ediyor. Modelimiz bunu buldu. İyi ama bunun doğru olduğunu nerden bilecez? 🧐 İşte bütün olay bu! Bu örneğin hangi türe ait olduğunu bilmiyoruz.

## Modelin Değerlendirilmesi

İşte burada daha önce oluşturduğumuz test set verisi önem arz ediyor. Bundaki veriler model oluşturmak için kullanılmadı. Ancak test setteki çiçeklerin hangi türe ait olduğunu biliyoruz. Öyleyse her bir çiçek için tahmin yapabilir ve bunları doğruları ile kıyaslayabiliriz. Modelin ne kadar iyi çalıştığını öğrenmek için _accuracy_'i hesaplayabiliriz.

```py:In
y_pred = knn.predict(X_test)
print("Test set predictions:\n {}".format(y_pred))
```

```:Out
Test set predictions:
    [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0 2]
```

```py:In
print("Test set score: {:.2f}".format(np.mean(y_pred == y_test)))
```

```:Out
Test set score: 0.97
```

Ayrıca, knn objesinin `score` metodu ile test set'in _accuracy_ sini hesaplatabiliriz.

```py:In
print("Test set score: {:.2f}".format(knn.score(X_test, y_test)))
```

```:Out
Test set score: 0.97
```

Bu model için test setin _accuracy_ değeri 0.97 çıktı, bu da modelimizin test setteki irislerin 97% sini doğru tahmin ettiği anlamına geliyor. Yani matematiksel varsayım olarak "Bu model yeni çiçeklerin türünü 97% ihtimalle doğru tahmin eder" diyebiliriz. Hobi olarak botanikle uğraşan biri olarak tahminler için bu model yeterince güvenilir bir model.
